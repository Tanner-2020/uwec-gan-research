{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4a1f7f8e1a034a6f99707398b5197dc6",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## 1: Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "d2709d12992641cf906feaf4ac110e76",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6429,
    "execution_start": 1672699657073,
    "source_hash": "2f1bf460",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2 # Needed custom Docker file, but all issues now resolved!\n",
    "import seaborn as sns\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing, Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "except:\n",
    "    from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "f0704d6e5b8b47b59684928ff15f3b2d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1672699663535,
    "source_hash": "b8e714e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOISE_DIM = 100  \n",
    "BATCH_SIZE = 4 \n",
    "STEPS_PER_EPOCH = 3750\n",
    "EPOCHS = 50\n",
    "SEED = 40\n",
    "WIDTH, HEIGHT, CHANNELS = 128, 128, 1\n",
    "\n",
    "OPTIMIZER = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasTumor = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "459c5b755722403089b21295909fd07d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1672699663542,
    "source_hash": "ee362ca3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if hasTumor == True:\n",
    "    MAIN_DIR = \"../cnn-gan-data/Br35H/tumorous\"\n",
    "else:\n",
    "    MAIN_DIR = \"../cnn-gan-data/Br35H/nontumorous\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e7bdbe936c7644b4a095ed0a46b3b1f0",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## 2: Image Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "444b94fc34404d80af8aed743496f4d6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1672699663552,
    "source_hash": "a2f0998d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    \n",
    "    imgs = []\n",
    "    target = 1\n",
    "    labels = []\n",
    "    for i in os.listdir(folder):\n",
    "        img_dir = os.path.join(folder,i)\n",
    "        try:\n",
    "            img = cv2.imread(img_dir)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (128,128))\n",
    "            imgs.append(img)\n",
    "            labels.append(target)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    imgs = np.array(imgs)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b709ed9970be428c87994aae8875c3f6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5903,
    "execution_start": 1672699663594,
    "source_hash": "88862bf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data, labels = load_images(MAIN_DIR)\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "dc293ba4df114446ad384658204aecde",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5,
    "execution_start": 1672699669496,
    "source_hash": "bc97809d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "idxs = np.random.randint(0, 155, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6e4a35984bc5462d857d13e6aad527b1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1672699669509,
    "source_hash": "729fb282",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = data[idxs]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dbbf93137c2c4347b95f49602a652cde",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1672699669524,
    "source_hash": "9bcbcd7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize the Images\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# Reshape images \n",
    "X_train = X_train.reshape(-1, WIDTH,HEIGHT,CHANNELS)\n",
    "\n",
    "# Check shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dca53ffe62d04c66b6dd401ffe1e0039",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1834,
    "execution_start": 1672699669539,
    "source_hash": "f631381c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "for i in range(10):\n",
    "    axs = plt.subplot(2,5,i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    axs.set_xticklabels([])\n",
    "    axs.set_yticklabels([])\n",
    "    plt.subplots_adjust(wspace=None, hspace=None)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e68353de21884496a639f57478e50458",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## 3: dc-GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "6b5cdbbffc8e461881f67e9840e81bb3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1001917,
    "execution_start": 1672699671361,
    "source_hash": "4ac2e8ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential([\n",
    "\n",
    "        Dense(32*32*256, input_dim=NOISE_DIM),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        Reshape((32,32,256)),\n",
    "        \n",
    "        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh')\n",
    "    ], \n",
    "    name=\"generator\")\n",
    "    model.summary()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "d8859eaadb5547f784b1e0ea3fb93429",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1022948,
    "execution_start": 1672699671362,
    "source_hash": "97f8bfcf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential([\n",
    "\n",
    "        Conv2D(64, (3, 3), padding='same', input_shape=(WIDTH, HEIGHT, CHANNELS)),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(128, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "\n",
    "        Conv2D(128, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        Conv2D(256, (3, 3), strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation=\"sigmoid\", input_shape=(WIDTH, HEIGHT, CHANNELS))\n",
    "    ], name=\"discriminator\")\n",
    "    model.summary()\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                        optimizer=OPTIMIZER)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ae773ee0a32474cbfe7860e75191236",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": [],
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "## 4: Combining Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "734726462745466ba99c90009336c90d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1001,
    "execution_start": 1672699671405,
    "source_hash": "f39cc1fc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "discriminator = build_discriminator()\n",
    "print('\\n')\n",
    "generator = build_generator()\n",
    "\n",
    "discriminator.trainable = False \n",
    "\n",
    "gan_input = Input(shape=(NOISE_DIM,))\n",
    "fake_image = generator(gan_input)\n",
    "\n",
    "gan_output = discriminator(fake_image)\n",
    "\n",
    "gan = Model(gan_input, gan_output, name=\"gan_model\")\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
    "\n",
    "print(\"The Combined Network:\\n\")\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "896e03b265ac4e97aac215b513b88d30",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 641445,
    "execution_start": 1672699672414,
    "source_hash": "f6ecf3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_images(noise, subplots, figsize=(22,8), save=False):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i, image in enumerate(generated_images):\n",
    "        plt.subplot(subplots[0], subplots[1], i+1)\n",
    "        if CHANNELS == 1:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT)), cmap='gray')    \n",
    "                                                                            \n",
    "        else:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT, CHANNELS)))\n",
    "        if save == True:\n",
    "            img_name = \"gen\" + str(i)\n",
    "            if hasTumor == True:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/yes-tumor/unrolled-images/\"+img_name)\n",
    "            else:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/no-tumor/unrolled-images/\"+img_name)\n",
    "        plt.subplots_adjust(wspace=None, hspace=None)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_saves(noise, num, figsize=(22,8)):\n",
    "    generated_images = generator.predict(noise)\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    for i, image in enumerate(generated_images):\n",
    "        if CHANNELS == 1:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT)), cmap='gray')    \n",
    "                                                                            \n",
    "        else:\n",
    "            plt.imshow(image.reshape((WIDTH, HEIGHT, CHANNELS)))\n",
    "        img_name = \"gen\" + str(i)\n",
    "        plt.axis('off')\n",
    "        if hasTumor == True:\n",
    "            if EPOCHS == 5:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/yes-tumor/unrolled-images/Epochs5/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 15:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/yes-tumor/unrolled-images/Epochs15/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 25:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/yes-tumor/unrolled-images/Epochs25/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 50:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/yes-tumor/unrolled-images/Epochs50/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "        else:\n",
    "            if EPOCHS == 5:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/no-tumor/unrolled-images/Epochs5/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 15:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/no-tumor/unrolled-images/Epochs15/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 25:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/no-tumor/unrolled-images/Epochs25/\"+img_name, bbox_inches=\"tight\", pad_inches=0)\n",
    "            if EPOCHS == 50:\n",
    "                plt.savefig(\"../cnn-gan-data/train-images/no-tumor/unrolled-images/Epochs50/\"+img_name, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_loss(X, disc_y, pseudodiscriminator):\n",
    "    # five unrollings.  Change to taste.\n",
    "    for i in range(5):\n",
    "        #train the discriminator forward a few steps\n",
    "        pseudo_loss = pseudodiscriminator.train_on_batch(X, disc_y)\n",
    "    return pseudo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "pseudodiscriminator = build_discriminator()\n",
    "pseudodiscriminator.trainable = False \n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in tqdm(range(STEPS_PER_EPOCH)):\n",
    "\n",
    "        noise = np.random.normal(0,1, size=(BATCH_SIZE, NOISE_DIM))\n",
    "        fake_X = generator.predict(noise)\n",
    "        \n",
    "        idx = np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)\n",
    "        real_X = X_train[idx]\n",
    "\n",
    "        X = np.concatenate((real_X, fake_X))\n",
    "\n",
    "        disc_y = np.zeros(2*BATCH_SIZE)\n",
    "        disc_y[:BATCH_SIZE] = 1\n",
    "        \n",
    "        y_gen = np.ones(BATCH_SIZE)\n",
    "        d_loss = pseudo_loss(X, disc_y, pseudodiscriminator)\n",
    "        g_loss = gan.train_on_batch(noise, y_gen)\n",
    "        d_loss = discriminator.train_on_batch(X, disc_y)\n",
    "\n",
    "    print(f\"EPOCH: {epoch + 1} Generator Loss: {g_loss:.4f} Discriminator Loss: {d_loss:.4f}\")\n",
    "    noise = np.random.normal(0, 1, size=(10,NOISE_DIM))\n",
    "    sample_images(noise, (2,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5: Generated Images Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, size=(500, NOISE_DIM))\n",
    "sample_images(noise, (50,10), (24,20), save=False)\n",
    "image_saves(noise, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generated Sample Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_images = generator.predict(noise)\n",
    "generated_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols = 1, nrows = 1, figsize = (18, 10))\n",
    "\n",
    "sns.distplot(X_train, label='Real Images', hist=True, color='#fc0328', ax=axs)\n",
    "sns.distplot(generated_images, label = 'Generated Images', hist = True, color = \"#0c06c7\", ax = axs)\n",
    "\n",
    "axs.legend(loc = 'upper right', prop = {'size': 12})\n",
    "\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "10e0f6c21e564efb9f375b1de0a88ec4",
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.8]",
   "language": "python",
   "name": "conda-env-tensorflow-2.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
