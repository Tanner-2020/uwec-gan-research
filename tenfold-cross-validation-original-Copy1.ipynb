{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9f00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.metrics as metrics\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e6fc7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ganMode = \"DC\"\n",
    "genEpochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324cf9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convNeuralNet(train_images, train_labels, test_images, test_labels):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,2)))\n",
    "    model.add(layers.Conv2D(96, (3, 3), activation='relu'))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    images = np.expand_dims(train_images, axis = -1)\n",
    "    test_images = np.expand_dims(test_images, axis = -1)\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tfa.metrics.F1Score(num_classes = 1)])\n",
    "\n",
    "    hisotry = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "    \n",
    "    test_loss, test_acc, test_prec, test_rec, test_fscore = model.evaluate(test_images, test_labels, verbose=2)\n",
    "    return (test_acc, test_prec, test_rec, test_fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c16bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avg_acc = 0\n",
    "count = 0\n",
    "low_acc = 0\n",
    "high_acc = 0\n",
    "avg_prec = 0\n",
    "low_prec = 0\n",
    "high_prec = 0\n",
    "avg_rec = 0\n",
    "low_rec = 0\n",
    "high_rec = 0\n",
    "avg_f1s = 0\n",
    "low_f1s = 0\n",
    "high_f1s = 0\n",
    "for comb in itertools.combinations([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 8):\n",
    "    \n",
    "    ## Clears lists before each loading\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    \n",
    "    # Loading of real images for each trial\n",
    "    for val in range(1, 11):\n",
    "        if comb.count(val) > 0:\n",
    "            for i in range((150*(val-1)), (150*val)):\n",
    "                image = cv2.imread(os.path.join(\"../cnn-gan-data/Br35H/nontumorous/\",\"no{i}.jpg\".format(i=i)))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (128, 128))\n",
    "                train_images.append(image)\n",
    "                train_labels.append(0)\n",
    "                image = cv2.imread(os.path.join(\"../cnn-gan-data/Br35H/tumorous/\",\"y{i}.jpg\".format(i=i)))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (128, 128))\n",
    "                train_images.append(image)\n",
    "                train_labels.append(1)\n",
    "        else:\n",
    "            for i in range((150*(val-1)), (150*val)):\n",
    "                image = cv2.imread(os.path.join(\"../cnn-gan-data/Br35H/nontumorous/\",\"no{i}.jpg\".format(i=i)))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (128, 128))\n",
    "                test_images.append(image)\n",
    "                test_labels.append(0)\n",
    "                image = cv2.imread(os.path.join(\"../cnn-gan-data/Br35H/tumorous/\",\"y{i}.jpg\".format(i=i)))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.resize(image, (128, 128))\n",
    "                test_images.append(image)\n",
    "                test_labels.append(1)\n",
    "          \n",
    "    # Loading of fake images for each trial\n",
    "    if ganMode != 'None':\n",
    "        if ganMode == 'DC':\n",
    "            tumorPath = '../cnn-gan-data/train-images/yes-tumor/dcgan-images'\n",
    "            noTumorPath = '../cnn-gan-data/train-images/no-tumor/dcgan-images'\n",
    "        if ganMode == 'Unrolled':\n",
    "            tumorPath = '../cnn-gan-data/train-images/yes-tumor/unrolled-images'\n",
    "            noTumorPath = '../cnn-gan-data/train-images/no-tumor/unrolled-images'\n",
    "        if ganMode == 'W':\n",
    "            tumorPath = '../cnn-gan-data/train-images/yes-tumor/wgan-images'\n",
    "            noTumorPath = '../cnn-gan-data/train-images/no-tumor/wgan-images'\n",
    "\n",
    "        if genEpochs == 5:\n",
    "            tumorPath = tumorPath + '/Epochs5'\n",
    "            noTumorPath = noTumorPath + '/Epochs5'\n",
    "        if genEpochs == 15:\n",
    "            tumorPath = tumorPath + '/Epochs15'\n",
    "            noTumorPath = noTumorPath + '/Epochs15'\n",
    "        if genEpochs == 25:\n",
    "            tumorPath = tumorPath + '/Epochs25'\n",
    "            noTumorPath = noTumorPath +'/Epochs25'\n",
    "        if genEpochs == 50:\n",
    "            tumorPath = tumorPath + '/Epochs50'\n",
    "            noTumorPath = noTumorPath +'/Epochs50'\n",
    "            \n",
    "        \n",
    "        for image_name in os.listdir(noTumorPath):\n",
    "            img_dir = os.path.join(noTumorPath, image_name)\n",
    "            image = cv2.imread(img_dir)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            train_images.append(image)\n",
    "            train_labels.append(0)\n",
    "        \n",
    "        for image_name in os.listdir(tumorPath):\n",
    "            img_dir = os.path.join(tumorPath, image_name)\n",
    "            image = cv2.imread(img_dir)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (128, 128))\n",
    "            train_images.append(image)\n",
    "            train_labels.append(1)\n",
    "    \n",
    "    # Converting lists to numpy arrays\n",
    "    train_images = np.array(train_images)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "    \n",
    "    # Increments trial count, runs trial, and outputs results\n",
    "    count += 1\n",
    "    metrics = convNeuralNet(train_images, train_labels, test_images, test_labels)\n",
    "    if low_acc == 0 or low_acc > metrics[0]:\n",
    "        low_acc = metrics[0]\n",
    "    if high_acc < metrics[0]:\n",
    "        high_acc = metrics[0]\n",
    "    print(\"Trial {n} accuracy: {acc}\".format(n=count, acc=metrics[0]))\n",
    "    avg_acc += metrics[0]\n",
    "    \n",
    "    if low_prec == 0 or low_prec > metrics[1]:\n",
    "        low_prec = metrics[1]\n",
    "    if high_prec < metrics[1]:\n",
    "        high_prec = metrics[1]\n",
    "    print(\"Trial {n} precision: {prec}\".format(n=count, prec=metrics[1]))\n",
    "    avg_prec += metrics[1]\n",
    "    \n",
    "    if low_rec == 0 or low_rec > metrics[2]:\n",
    "        low_rec = metrics[2]\n",
    "    if high_rec < metrics[2]:\n",
    "        high_rec = metrics[2]\n",
    "    print(\"Trial {n} recall: {rec}\".format(n=count, rec=metrics[2]))\n",
    "    avg_rec += metrics[2]\n",
    "    \n",
    "    if low_f1s == 0 or low_f1s > metrics[3]:\n",
    "        low_f1s = metrics[3]\n",
    "    if high_f1s < metrics[3]:\n",
    "        high_f1s = metrics[3]\n",
    "    print(\"Trial {n} F1Score: {f1s}\".format(n=count, f1s=metrics[3]))\n",
    "    avg_f1s += metrics[3]\n",
    "\n",
    "avg_acc = avg_acc/count\n",
    "print(\"Average accuracy of all trials: {avg_acc}\".format(avg_acc=avg_acc))\n",
    "print(\"Lowest accuracy of all trials: {low_acc}\".format(low_acc=low_acc))\n",
    "print(\"Highest accuracy of all trials: {high_acc}\".format(high_acc=high_acc))\n",
    "\n",
    "avg_prec = avg_prec/count\n",
    "print(\"Average precision of all trials: {avg_prec}\".format(avg_prec=avg_prec))\n",
    "print(\"Lowest precision of all trials: {low_prec}\".format(low_prec=low_prec))\n",
    "print(\"Highest precision of all trials: {high_prec}\".format(high_prec=high_prec))\n",
    "\n",
    "avg_rec = avg_rec/count\n",
    "print(\"Average recall of all trials: {avg_rec}\".format(avg_rec=avg_rec))\n",
    "print(\"Lowest recall of all trials: {low_rec}\".format(low_rec=low_rec))\n",
    "print(\"Highest recall of all trials: {high_rec}\".format(high_rec=high_rec))\n",
    "\n",
    "avg_f1s = avg_f1s/count\n",
    "print(\"Average FScore of all trials: {avg_f1s}\".format(avg_f1s=avg_f1s))\n",
    "print(\"Lowest FScore of all trials: {low_f1s}\".format(low_f1s=low_f1s))\n",
    "print(\"Highest FScore of all trials: {high_f1s}\".format(high_f1s=high_f1s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.8]",
   "language": "python",
   "name": "conda-env-tensorflow-2.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
